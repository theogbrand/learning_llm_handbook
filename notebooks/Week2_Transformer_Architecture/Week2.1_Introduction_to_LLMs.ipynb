{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Large Language Models: A Step-by-Step Journey\n",
    "\n",
    "## Our Goal\n",
    "\n",
    "In this notebook, we will understand how language models predict text by following the complete process of predicting \"we love deep learning\" word by word. We'll explore four fundamental concepts that make modern language models like ChatGPT work:\n",
    "\n",
    "1. **Forward Pass**: How models generate predictions\n",
    "2. **Loss Calculation**: How we measure prediction quality\n",
    "3. **Backpropagation**: How we identify what needs improvement\n",
    "4. **Gradient Descent**: How we make those improvements\n",
    "\n",
    "## Our Vocabulary and Target\n",
    "\n",
    "We'll work with a simple vocabulary to keep things clear and manageable. Our model will learn to predict each word in our target sequence step by step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY: ['<BOS>', 'we', 'love', 'deep', 'learning', '<EOS>', 'the', 'is', 'great', 'model', 'hello', 'world']\n",
      "TARGET SEQUENCE: ['we', 'love', 'deep', 'learning']\n",
      "VOCABULARY SIZE: 12\n",
      "\n",
      "Initial model parameters (simplified representation):\n",
      "Layer 1 weights: 12 parameters\n",
      "Layer 2 weights: 12 parameters\n",
      "Output weights: 12 parameters\n"
     ]
    }
   ],
   "source": [
    "# Setup our simple vocabulary and target sequence\n",
    "VOCAB = [\"<BOS>\", \"we\", \"love\", \"deep\", \"learning\", \"<EOS>\", \"the\", \"is\", \"great\", \"model\", \"hello\", \"world\"]\n",
    "target_sequence = [\"we\", \"love\", \"deep\", \"learning\"]\n",
    "\n",
    "print(\"VOCABULARY:\", VOCAB)\n",
    "print(\"TARGET SEQUENCE:\", target_sequence)\n",
    "print(\"VOCABULARY SIZE:\", len(VOCAB))\n",
    "\n",
    "# Initialize simple model parameters (weights) - these will be updated during training\n",
    "# In real models, these would be millions or billions of parameters\n",
    "model_parameters = {\n",
    "    'layer1_weights': [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.8, -0.2, 0.3, -0.5, 0.7, -0.4],\n",
    "    'layer2_weights': [0.2, 0.1, -0.4, 0.6, 0.3, -0.2, -0.1, 0.5, -0.3, 0.4, -0.6, 0.1],\n",
    "    'output_weights': [0.3, -0.1, 0.4, -0.2, 0.5, 0.1, -0.3, 0.2, 0.6, -0.4, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "print(\"\\nInitial model parameters (simplified representation):\")\n",
    "print(\"Layer 1 weights:\", len(model_parameters['layer1_weights']), \"parameters\")\n",
    "print(\"Layer 2 weights:\", len(model_parameters['layer2_weights']), \"parameters\") \n",
    "print(\"Output weights:\", len(model_parameters['output_weights']), \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Logits?\n",
    "\n",
    "Logits are the raw numerical scores that a language model assigns to every word in its vocabulary when predicting the next word. Think of logits as the model's initial \"gut feeling\" about how likely each word is to come next, before any normalization.\n",
    "\n",
    "**Key Properties of Logits:**\n",
    "\n",
    "- They can be any real number (positive, negative, large, small)\n",
    "- Higher logits indicate the model thinks a word is more likely\n",
    "- Lower logits indicate the model thinks a word is less likely\n",
    "- They are computed by passing the current context through the neural network layers\n",
    "\n",
    "Let's see what logits look like when our model tries to predict the first word after the beginning-of-sequence token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit scores for predicting first word after <BOS>:\n",
      "==================================================\n",
      "the       :    3.2\n",
      "hello     :    2.8\n",
      "we        :    2.1 <- Our target!\n",
      "is        :    1.5\n",
      "love      :   -0.5\n",
      "deep      :   -1.2\n",
      "learning  :   -2.0\n",
      "<EOS>     :  -10.0\n",
      "\n",
      "Notice how 'the' has the highest logit (3.2) because it's\n",
      "the most common way to start sentences in English.\n",
      "Our target word 'we' has a logit of 2.1, which is decent\n",
      "but not the highest - the model will need training to improve this!\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_logits():\n",
    "    # Pre-calculated realistic logit values for predicting first word after <BOS>\n",
    "    logits_after_bos = {\n",
    "        \"we\": 2.1,      # Target word - decent score\n",
    "        \"the\": 3.2,     # Highest - most common starter\n",
    "        \"hello\": 2.8,   # High - common greeting\n",
    "        \"is\": 1.5,      # Medium - possible starter\n",
    "        \"love\": -0.5,   # Low - uncommon starter\n",
    "        \"deep\": -1.2,   # Lower - rare starter\n",
    "        \"learning\": -2.0, # Very low - very rare starter\n",
    "        \"<EOS>\": -10.0, # Impossible - can't start with end token\n",
    "    }\n",
    "    \n",
    "    print(\"Logit scores for predicting first word after <BOS>:\")\n",
    "    print(\"=\" * 50)\n",
    "    for word, logit in sorted(logits_after_bos.items(), key=lambda x: x[1], reverse=True):\n",
    "        marker = \" <- Our target!\" if word == \"we\" else \"\"\n",
    "        print(f\"{word:10}: {logit:6.1f}{marker}\")\n",
    "    \n",
    "    print(f\"\\nNotice how 'the' has the highest logit ({logits_after_bos['the']}) because it's\")\n",
    "    print(\"the most common way to start sentences in English.\")\n",
    "    print(f\"Our target word 'we' has a logit of {logits_after_bos['we']}, which is decent\")\n",
    "    print(\"but not the highest - the model will need training to improve this!\")\n",
    "    \n",
    "    return logits_after_bos\n",
    "\n",
    "# Run the demonstration\n",
    "logits_step1 = demonstrate_logits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Logits to Probabilities: The Softmax Operation\n",
    "\n",
    "Raw logits are useful for the model internally, but they're not easy for us to interpret. We need to convert them into probabilities - numbers between 0 and 1 that sum to exactly 1.0. This conversion is done using the **softmax function**.\n",
    "\n",
    "**The Softmax Process:**\n",
    "\n",
    "1. Calculate e^(logit) for each word (this makes all values positive)\n",
    "2. Sum all these exponential values\n",
    "3. Divide each exponential value by the sum\n",
    "\n",
    "This ensures we get valid probabilities that represent the model's confidence in each possible next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOFTMAX CONVERSION: From Logits to Probabilities\n",
      "=======================================================\n",
      "STEP 1: Calculate e^(logit) for each word\n",
      "----------------------------------------\n",
      "e^(  2.1) =     8.17  for 'we'\n",
      "e^(  3.2) =    24.53  for 'the'\n",
      "e^(  2.8) =    16.44  for 'hello'\n",
      "e^(  1.5) =     4.48  for 'is'\n",
      "e^( -0.5) =     0.61  for 'love'\n",
      "e^( -1.2) =     0.30  for 'deep'\n",
      "e^( -2.0) =     0.14  for 'learning'\n",
      "e^(-10.0) =     0.00  for '<EOS>'\n",
      "\n",
      "STEP 2: Sum all exponential values\n",
      "-----------------------------------\n",
      "Total sum = 54.67\n",
      "\n",
      "STEP 3: Calculate final probabilities\n",
      "--------------------------------------\n",
      "P(we      ) =     8.17 / 54.67 = 0.1494 <- Our target!\n",
      "P(the     ) =    24.53 / 54.67 = 0.4488\n",
      "P(hello   ) =    16.44 / 54.67 = 0.3008\n",
      "P(is      ) =     4.48 / 54.67 = 0.0820\n",
      "P(love    ) =     0.61 / 54.67 = 0.0111\n",
      "P(deep    ) =     0.30 / 54.67 = 0.0055\n",
      "P(learning) =     0.14 / 54.67 = 0.0025\n",
      "P(<EOS>   ) =     0.00 / 54.67 = 0.0000\n",
      "\n",
      "Verification: All probabilities sum to 1.000000\n",
      "\n",
      "Key insight: 'the' had the highest logit\n",
      "and now has the highest probability (0.4488)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def demonstrate_softmax(logits_dict):\n",
    "    print(\"SOFTMAX CONVERSION: From Logits to Probabilities\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    words = list(logits_dict.keys())\n",
    "    logits = list(logits_dict.values())\n",
    "    \n",
    "    print(\"STEP 1: Calculate e^(logit) for each word\")\n",
    "    print(\"-\" * 40)\n",
    "    exp_logits = []\n",
    "    for word, logit in zip(words, logits):\n",
    "        exp_val = math.exp(logit)\n",
    "        exp_logits.append(exp_val)\n",
    "        print(f\"e^({logit:5.1f}) = {exp_val:8.2f}  for '{word}'\")\n",
    "    \n",
    "    print(f\"\\nSTEP 2: Sum all exponential values\")\n",
    "    print(\"-\" * 35)\n",
    "    total = sum(exp_logits)\n",
    "    print(f\"Total sum = {total:.2f}\")\n",
    "    \n",
    "    print(f\"\\nSTEP 3: Calculate final probabilities\")\n",
    "    print(\"-\" * 38)\n",
    "    probabilities = {}\n",
    "    for word, exp_val in zip(words, exp_logits):\n",
    "        prob = exp_val / total\n",
    "        probabilities[word] = prob\n",
    "        marker = \" <- Our target!\" if word == \"we\" else \"\"\n",
    "        print(f\"P({word:8}) = {exp_val:8.2f} / {total:.2f} = {prob:.4f}{marker}\")\n",
    "    \n",
    "    print(f\"\\nVerification: All probabilities sum to {sum(probabilities.values()):.6f}\")\n",
    "    print(f\"\\nKey insight: '{max(logits_dict, key=logits_dict.get)}' had the highest logit\")\n",
    "    print(f\"and now has the highest probability ({max(probabilities.values()):.4f})\")\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Convert our logits to probabilities\n",
    "probabilities_step1 = demonstrate_softmax(logits_step1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Prediction: How Context Shapes Predictions\n",
    "\n",
    "Language models don't just predict single words in isolation - they use the entire preceding context to make increasingly informed predictions. As we build up the sequence \"we love deep learning,\" each new word provides more context that helps the model make better predictions for the next word.\n",
    "\n",
    "Let's observe how the model's logit scores change as we provide more context at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE SEQUENCE PREDICTION: 'we love deep learning'\n",
      "============================================================\n",
      "\n",
      "STEP 1: Context = '<BOS>' -> Predicting 'we'\n",
      "----------------------------------------------------------------------\n",
      "Top 5 logit scores:\n",
      "  1. the       :    3.2\n",
      "  2. hello     :    2.8\n",
      "  3. we        :    2.1 ** TARGET **\n",
      "  4. is        :    1.5\n",
      "  5. love      :   -0.5\n",
      "\n",
      "Target word 'we' probability: 0.149\n",
      "Context effect: 'we' is a common sentence starter, though 'the' is even more common in general text\n",
      "\n",
      "STEP 2: Context = 'we' -> Predicting 'love'\n",
      "----------------------------------------------------------------------\n",
      "Top 5 logit scores:\n",
      "  1. love      :    2.8 ** TARGET **\n",
      "  2. is        :    2.1\n",
      "  3. the       :    1.2\n",
      "  4. deep      :   -0.5\n",
      "  5. learning  :   -1.5\n",
      "\n",
      "Target word 'love' probability: 0.571\n",
      "Context effect: After 'we', action words like 'love', 'are', 'have' become much more likely than nouns\n",
      "\n",
      "STEP 3: Context = 'we love' -> Predicting 'deep'\n",
      "----------------------------------------------------------------------\n",
      "Top 5 logit scores:\n",
      "  1. deep      :    1.9 ** TARGET **\n",
      "  2. learning  :    0.8\n",
      "  3. the       :    0.5\n",
      "  4. is        :   -2.0\n",
      "  5. love      :   -4.0\n",
      "\n",
      "Target word 'deep' probability: 0.623\n",
      "Context effect: After 'we love', we expect objects or concepts; 'deep' scores well as it often precedes 'learning'\n",
      "\n",
      "STEP 4: Context = 'we love deep' -> Predicting 'learning'\n",
      "----------------------------------------------------------------------\n",
      "Top 5 logit scores:\n",
      "  1. learning  :    3.5 ** TARGET **\n",
      "  2. the       :   -2.0\n",
      "  3. is        :   -3.0\n",
      "  4. deep      :   -4.0\n",
      "  5. love      :   -5.0\n",
      "\n",
      "Target word 'learning' probability: 0.994\n",
      "Context effect: 'deep learning' is a common collocation - 'learning' becomes very likely after 'deep' in this context\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_sequence_prediction():\n",
    "    print(\"COMPLETE SEQUENCE PREDICTION: 'we love deep learning'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Pre-calculated logits for each prediction step showing how context improves predictions\n",
    "    prediction_steps = [\n",
    "        {\n",
    "            \"step\": 1,\n",
    "            \"context\": \"<BOS>\",\n",
    "            \"target\": \"we\", \n",
    "            \"logits\": {\"we\": 2.1, \"love\": -0.5, \"deep\": -1.2, \"learning\": -2.0, \"the\": 3.2, \"hello\": 2.8, \"is\": 1.5, \"<EOS>\": -10.0},\n",
    "            \"explanation\": \"'we' is a common sentence starter, though 'the' is even more common in general text\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 2,\n",
    "            \"context\": \"we\",\n",
    "            \"target\": \"love\",\n",
    "            \"logits\": {\"we\": -3.0, \"love\": 2.8, \"deep\": -0.5, \"learning\": -1.5, \"the\": 1.2, \"hello\": -5.0, \"is\": 2.1, \"<EOS>\": -8.0},\n",
    "            \"explanation\": \"After 'we', action words like 'love', 'are', 'have' become much more likely than nouns\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 3,\n",
    "            \"context\": \"we love\",\n",
    "            \"target\": \"deep\",\n",
    "            \"logits\": {\"we\": -5.0, \"love\": -4.0, \"deep\": 1.9, \"learning\": 0.8, \"the\": 0.5, \"hello\": -6.0, \"is\": -2.0, \"<EOS>\": -7.0},\n",
    "            \"explanation\": \"After 'we love', we expect objects or concepts; 'deep' scores well as it often precedes 'learning'\"\n",
    "        },\n",
    "        {\n",
    "            \"step\": 4,\n",
    "            \"context\": \"we love deep\",\n",
    "            \"target\": \"learning\",\n",
    "            \"logits\": {\"we\": -6.0, \"love\": -5.0, \"deep\": -4.0, \"learning\": 3.5, \"the\": -2.0, \"hello\": -8.0, \"is\": -3.0, \"<EOS>\": -6.0},\n",
    "            \"explanation\": \"'deep learning' is a common collocation - 'learning' becomes very likely after 'deep' in this context\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    all_step_probabilities = []\n",
    "    \n",
    "    for step_info in prediction_steps:\n",
    "        print(f\"\\nSTEP {step_info['step']}: Context = '{step_info['context']}' -> Predicting '{step_info['target']}'\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Show top 5 logits\n",
    "        sorted_logits = sorted(step_info['logits'].items(), key=lambda x: x[1], reverse=True)\n",
    "        print(\"Top 5 logit scores:\")\n",
    "        for i, (word, logit) in enumerate(sorted_logits[:5]):\n",
    "            marker = \" ** TARGET **\" if word == step_info['target'] else \"\"\n",
    "            print(f\"  {i+1}. {word:10}: {logit:6.1f}{marker}\")\n",
    "        \n",
    "        # Calculate probability for target word\n",
    "        target_logit = step_info['logits'][step_info['target']]\n",
    "        exp_values = [math.exp(logit) for logit in step_info['logits'].values()]\n",
    "        total_exp = sum(exp_values)\n",
    "        target_prob = math.exp(target_logit) / total_exp\n",
    "        all_step_probabilities.append(target_prob)\n",
    "        \n",
    "        print(f\"\\nTarget word '{step_info['target']}' probability: {target_prob:.3f}\")\n",
    "        print(f\"Context effect: {step_info['explanation']}\")\n",
    "    \n",
    "    return prediction_steps, all_step_probabilities\n",
    "\n",
    "# Generate predictions for the complete sequence\n",
    "steps_data, step_probabilities = demonstrate_sequence_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function: Quantifying Prediction Quality\n",
    "\n",
    "The **loss function** is how we measure how well our model is performing. Specifically, it measures how \"surprised\" the model is when it sees the correct answer. The mathematical formulation we use is called **cross-entropy loss** or **log-likelihood loss**.\n",
    "\n",
    "**Key Concepts:**\n",
    "- Lower loss = better predictions = less surprise when seeing the correct answer\n",
    "- Higher loss = worse predictions = more surprise when seeing the correct answer  \n",
    "- Loss is calculated as: Loss = -log(probability of correct word)\n",
    "- Training aims to minimize the total loss across all predictions\n",
    "\n",
    "The logarithm has a useful property: it heavily penalizes very low probabilities. If the model assigns a probability of 0.01 to the correct word, the loss is much higher than if it assigns 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERSTANDING LOSS: Measuring Model Performance\n",
      "=======================================================\n",
      "Loss measures surprise: How unexpected was the correct answer?\n",
      "Formula: Loss = -log(probability of correct word)\n",
      "\n",
      "Example scenarios for predicting 'learning':\n",
      "--------------------------------------------------\n",
      "P(learning) = 0.85 -> Loss = 0.16 -> Very Low   surprise -> Excellent prediction\n",
      "P(learning) = 0.45 -> Loss = 0.80 -> Medium     surprise -> Decent prediction\n",
      "P(learning) = 0.15 -> Loss = 1.90 -> High       surprise -> Poor prediction\n",
      "P(learning) = 0.02 -> Loss = 3.91 -> Very High  surprise -> Terrible prediction\n",
      "\n",
      "Training Goal: Minimize total loss across all predictions!\n",
      "This means: Assign high probabilities to correct words\n",
      "\n",
      "LOSS CALCULATION FOR OUR SEQUENCE:\n",
      "----------------------------------------\n",
      "Step 1 - P(we      ) = 0.149 -> Loss = 1.901\n",
      "Step 2 - P(love    ) = 0.571 -> Loss = 0.561\n",
      "Step 3 - P(deep    ) = 0.623 -> Loss = 0.472\n",
      "Step 4 - P(learning) = 0.994 -> Loss = 0.006\n",
      "\n",
      "Total Loss for sequence = 2.941\n",
      "Average Loss per word = 0.735\n",
      "\n",
      "Lower total loss indicates better overall performance!\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_loss_calculation():\n",
    "    print(\"UNDERSTANDING LOSS: Measuring Model Performance\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    print(\"Loss measures surprise: How unexpected was the correct answer?\")\n",
    "    print(\"Formula: Loss = -log(probability of correct word)\")\n",
    "    print(\"\\nExample scenarios for predicting 'learning':\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scenarios = [\n",
    "        {\"probability\": 0.85, \"surprise_level\": \"Very Low\", \"quality\": \"Excellent prediction\"},\n",
    "        {\"probability\": 0.45, \"surprise_level\": \"Medium\", \"quality\": \"Decent prediction\"},\n",
    "        {\"probability\": 0.15, \"surprise_level\": \"High\", \"quality\": \"Poor prediction\"},\n",
    "        {\"probability\": 0.02, \"surprise_level\": \"Very High\", \"quality\": \"Terrible prediction\"}\n",
    "    ]\n",
    "    \n",
    "    for scenario in scenarios:\n",
    "        prob = scenario[\"probability\"]\n",
    "        loss = -math.log(prob)\n",
    "        print(f\"P(learning) = {prob:4.2f} -> Loss = {loss:4.2f} -> {scenario['surprise_level']:10} surprise -> {scenario['quality']}\")\n",
    "    \n",
    "    print(f\"\\nTraining Goal: Minimize total loss across all predictions!\")\n",
    "    print(f\"This means: Assign high probabilities to correct words\\n\")\n",
    "    \n",
    "    # Calculate loss for our actual sequence\n",
    "    print(\"LOSS CALCULATION FOR OUR SEQUENCE:\")\n",
    "    print(\"-\" * 40)\n",
    "    words = [\"we\", \"love\", \"deep\", \"learning\"]\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (word, prob) in enumerate(zip(words, step_probabilities)):\n",
    "        loss = -math.log(prob)\n",
    "        total_loss += loss\n",
    "        print(f\"Step {i+1} - P({word:8}) = {prob:.3f} -> Loss = {loss:.3f}\")\n",
    "    \n",
    "    print(f\"\\nTotal Loss for sequence = {total_loss:.3f}\")\n",
    "    print(f\"Average Loss per word = {total_loss/len(words):.3f}\")\n",
    "    print(\"\\nLower total loss indicates better overall performance!\")\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "# Calculate loss for our predictions\n",
    "sequence_loss = demonstrate_loss_calculation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
