{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Large Language Models: A Step-by-Step Journey\n",
    "\n",
    "## Our Goal\n",
    "In this notebook, we will understand how language models predict text by following the complete process of predicting \"we love deep learning\" word by word. We'll explore four fundamental concepts that make modern language models like ChatGPT work:\n",
    "\n",
    "1. **Forward Pass**: How models generate predictions\n",
    "2. **Loss Calculation**: How we measure prediction quality  \n",
    "3. **Backpropagation**: How we identify what needs improvement\n",
    "4. **Gradient Descent**: How we make those improvements\n",
    "\n",
    "## Our Vocabulary and Target\n",
    "We'll work with a simple vocabulary to keep things clear and manageable. Our model will learn to predict each word in our target sequence step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARY: ['<BOS>', 'we', 'love', 'deep', 'learning', '<EOS>', 'the', 'is', 'great', 'model', 'hello', 'world']\n",
      "TARGET SEQUENCE: ['we', 'love', 'deep', 'learning']\n",
      "VOCABULARY SIZE: 12\n",
      "\n",
      "Initial model parameters (simplified representation):\n",
      "Layer 1 weights: 12 parameters\n",
      "Layer 2 weights: 12 parameters\n",
      "Output weights: 12 parameters\n"
     ]
    }
   ],
   "source": [
    "# Setup our simple vocabulary and target sequence\n",
    "VOCAB = [\"<BOS>\", \"we\", \"love\", \"deep\", \"learning\", \"<EOS>\", \"the\", \"is\", \"great\", \"model\", \"hello\", \"world\"]\n",
    "target_sequence = [\"we\", \"love\", \"deep\", \"learning\"]\n",
    "\n",
    "print(\"VOCABULARY:\", VOCAB)\n",
    "print(\"TARGET SEQUENCE:\", target_sequence)\n",
    "print(\"VOCABULARY SIZE:\", len(VOCAB))\n",
    "\n",
    "# Initialize simple model parameters (weights) - these will be updated during training\n",
    "# In real models, these would be millions or billions of parameters\n",
    "model_parameters = {\n",
    "    'layer1_weights': [0.1, -0.3, 0.5, 0.2, -0.1, 0.4, 0.8, -0.2, 0.3, -0.5, 0.7, -0.4],\n",
    "    'layer2_weights': [0.2, 0.1, -0.4, 0.6, 0.3, -0.2, -0.1, 0.5, -0.3, 0.4, -0.6, 0.1],\n",
    "    'output_weights': [0.3, -0.1, 0.4, -0.2, 0.5, 0.1, -0.3, 0.2, 0.6, -0.4, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "print(\"\\nInitial model parameters (simplified representation):\")\n",
    "print(\"Layer 1 weights:\", len(model_parameters['layer1_weights']), \"parameters\")\n",
    "print(\"Layer 2 weights:\", len(model_parameters['layer2_weights']), \"parameters\") \n",
    "print(\"Output weights:\", len(model_parameters['output_weights']), \"parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are Logits?\n",
    "\n",
    "Logits are the raw numerical scores that a language model assigns to every word in its vocabulary when predicting the next word. Think of logits as the model's initial \"gut feeling\" about how likely each word is to come next, before any normalization.\n",
    "\n",
    "**Key Properties of Logits:**\n",
    "- They can be any real number (positive, negative, large, small)\n",
    "- Higher logits indicate the model thinks a word is more likely\n",
    "- Lower logits indicate the model thinks a word is less likely\n",
    "- They are computed by passing the current context through the neural network layers\n",
    "\n",
    "Let's see what logits look like when our model tries to predict the first word after the beginning-of-sequence token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit scores for predicting first word after <BOS>:\n",
      "==================================================\n",
      "the       :    3.2\n",
      "hello     :    2.8\n",
      "we        :    2.1 <- Our target!\n",
      "is        :    1.5\n",
      "love      :   -0.5\n",
      "deep      :   -1.2\n",
      "learning  :   -2.0\n",
      "<EOS>     :  -10.0\n",
      "\n",
      "Notice how 'the' has the highest logit (3.2) because it's\n",
      "the most common way to start sentences in English.\n",
      "Our target word 'we' has a logit of 2.1, which is decent\n",
      "but not the highest - the model will need training to improve this!\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_logits():\n",
    "    # Pre-calculated realistic logit values for predicting first word after <BOS>\n",
    "    logits_after_bos = {\n",
    "        \"we\": 2.1,      # Target word - decent score\n",
    "        \"the\": 3.2,     # Highest - most common starter\n",
    "        \"hello\": 2.8,   # High - common greeting\n",
    "        \"is\": 1.5,      # Medium - possible starter\n",
    "        \"love\": -0.5,   # Low - uncommon starter\n",
    "        \"deep\": -1.2,   # Lower - rare starter\n",
    "        \"learning\": -2.0, # Very low - very rare starter\n",
    "        \"<EOS>\": -10.0, # Impossible - can't start with end token\n",
    "    }\n",
    "    \n",
    "    print(\"Logit scores for predicting first word after <BOS>:\")\n",
    "    print(\"=\" * 50)\n",
    "    for word, logit in sorted(logits_after_bos.items(), key=lambda x: x[1], reverse=True):\n",
    "        marker = \" <- Our target!\" if word == \"we\" else \"\"\n",
    "        print(f\"{word:10}: {logit:6.1f}{marker}\")\n",
    "    \n",
    "    print(f\"\\nNotice how 'the' has the highest logit ({logits_after_bos['the']}) because it's\")\n",
    "    print(\"the most common way to start sentences in English.\")\n",
    "    print(f\"Our target word 'we' has a logit of {logits_after_bos['we']}, which is decent\")\n",
    "    print(\"but not the highest - the model will need training to improve this!\")\n",
    "    \n",
    "    return logits_after_bos\n",
    "\n",
    "# Run the demonstration\n",
    "logits_step1 = demonstrate_logits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
